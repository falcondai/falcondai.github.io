{"componentChunkName":"component---src-gatsby-theme-blog-core-templates-post-query-js","path":"/blog/watermark-llm-output/","result":{"data":{"site":{"siteMetadata":{"title":"Falcon Dai","author":"Falcon Dai","authorTwitter":"@falcondai","social":[{"name":"x","url":"https://x.com/falcondai"},{"name":"github","url":"https://github.com/falcondai"}]}},"blogPost":{"__typename":"MdxBlogPost","id":"96cc930d-a771-53d1-acba-dba6299e7e18","excerpt":"The increasingly capable LLMs and diffusion models are being used to generate more and more of the text and image content on the internet…","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"On Watermarking (Large) Language Model Output\",\n  \"date\": \"2024-03-19T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"The increasingly capable LLMs and diffusion models are being used to generate more and more of the text and image content on the internet. In order to counter the perceived danger of AI generated content, various organizations and policy making bodies have proposed to watermark such AI-generated content. One of my past \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1907.06679\"\n  }, \"research\"), \" presents an approach to this problem by reducing invisible watermarking to linguistic steganography. In \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Steganography\"\n  }, \"steganography\"), \", we try to hide the hiding by encoding a secret message in a natural looking message to assuage others' suspicion.\"), mdx(\"h2\", {\n    \"id\": \"what-is-steganography\"\n  }, \"What Is Steganography?\"), mdx(\"p\", null, \"As usual in cryptography, we can explain the steganography protocol with Alice and Bob. This time they role play as two prisoners who want to communicate with each other on an escape plan without alerting the warden who can read the messages. Standard encryption protocols usually produce messages (ciphertext) that look alien or \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"random\"), \". Even though the warden intercepting such messages won't be able to read their escape plan (plaintext), their \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"unnatural\"), \" appareance may be sufficient to land Alice and Bob in trouble. Steganography instead hides the message inside a natural looking text (stegotext) to evade scrutiny. More formally, we define \\\"naturalness\\\" as being plausible under the distribution of the objects in consideration. Fundamentally, encoding bits can disturb the carrier, so it is easy to hide a few bits in a high bandwidth carrier medium (in terms of information entropy). It is hard in the case of natural text because it has a much lower bandwidth than an audio recording or a printed page. This is the core problem my research tackled with improved algorithms. (For more details on the proposed algorithm \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"patient-Huffman\"), \", you could watch my \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://vimeo.com/385200929\"\n  }, \"talk\"), \".)\"), mdx(\"h2\", {\n    \"id\": \"invisible-watermarking---steganography\"\n  }, \"Invisible Watermarking -> Steganography\"), mdx(\"p\", null, \"In this reduction, an LLM service provider plays the roles of both Alice and Bob, and tries to encode a watermark in such a way that it can be recovered, thus verify whether the text is LLM-generated or not, later. LLM service users play the role of the warden. In the stegosystem I proposed, the LLM service provider will keep an encryption key and a watermark phrase as secrets.\"), mdx(\"h2\", {\n    \"id\": \"demo\"\n  }, \"Demo\"), mdx(\"p\", null, \"As an exercise to familiarize myself with the huggingface ecosystem, I built a live \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://falcondai-stego-lm.hf.space\"\n  }, \"demo\"), \". In order to invisibly watermark the generated content--in this case by GPT-2--, one can follow the steps on the sender side and enter \\\"by GPT-2\\\" as plaintext. The generated stegotext should be fluent (as much as sampling from a small GPT-2 model). When an auditor with the encryption key wishes to check if a piece of text was watermarked, they can follow the procedure of the receiver (Bob) in the stegosystem discussed. Importantly, observe that a piece of text not watermarked will trigger an error in the demo when being deciphered.\"));\n}\n;\nMDXContent.isMDXComponent = true;","slug":"/blog/watermark-llm-output/","title":"On Watermarking (Large) Language Model Output","tags":[],"keywords":[],"date":"March 19, 2024"},"previous":{"__typename":"MdxBlogPost","id":"60b60b0a-cdca-5109-8cb0-cdd243bc01cf","excerpt":"Due to the rapid empirical improvements in large language models (LLMs), there is a growing interests in robotics community to leverage them…","slug":"/blog/llm-robot-interaction/","title":"Large Language Models-powered Human-Robotic Interactions","date":"March 17, 2023"},"next":null},"pageContext":{"id":"96cc930d-a771-53d1-acba-dba6299e7e18","previousId":"60b60b0a-cdca-5109-8cb0-cdd243bc01cf"}},"staticQueryHashes":["4198970465","880678893"]}